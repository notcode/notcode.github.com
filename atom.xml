<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Not Code]]></title>
  <link href="http://notcode.github.io/atom.xml" rel="self"/>
  <link href="http://notcode.github.io/"/>
  <updated>2013-10-14T21:56:04+08:00</updated>
  <id>http://notcode.github.io/</id>
  <author>
    <name><![CDATA[coder]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[setup master slave replication on postgresql]]></title>
    <link href="http://notcode.github.io/blog/2013/10/14/setup-master-slave-replication-on-postgresql/"/>
    <updated>2013-10-14T13:04:00+08:00</updated>
    <id>http://notcode.github.io/blog/2013/10/14/setup-master-slave-replication-on-postgresql</id>
    <content type="html"><![CDATA[<h4>1. 常用的命令</h4>

<ul>
<li><p><code>pg_ctl init -D DIR -o "--no-locale"</code></p>

<p>初始化数据目录. <code>-o</code>表示要传递给initdb的参数. <code>--no-locale</code>将encoding设置为SQL_ASCII,Collation和Ctype设置为C,可以避免各种编码的问题.</p></li>
<li><p><code>pg_ctl start -D &lt;DATA DIR&gt; -l &lt;LOG FILE&gt;</code></p>

<p>启动pg</p></li>
<li><p><code>pg_ctl stop  -D &lt;DATA DIR&gt;</code></p>

<p>停止pg</p></li>
<li><p><code>pg_dump &lt;DBNAME&gt; [-t &lt;TBNAME&gt;]...</code></p>

<p>导出数据库/表</p></li>
</ul>


<!-- more -->


<h4>2. 配置master slave replication</h4>

<h5>注意</h5>

<ul>
<li>需要先有一个可用的master server。不需要有一个可用的slave server</li>
<li>配置过程中需要将master的数据目录rsync到slave机器上</li>
<li>最后在slave机器上启动pg服务</li>
</ul>


<h5>master端</h5>

<ol>
<li><p> 修改postgresl.conf配置文件中的如下配置项：</p>

<pre><code>wal_level=hot_standby

max_wal_senders=5

wal_keep_segments=32
</code></pre></li>
<li><p> 修改pg_hba.conf,增加:</p>

<pre><code>host replication    &lt;USER&gt; &lt;NETWORK/MASK&gt;   trust
</code></pre></li>
<li><p> 重启master</p></li>
<li><p> 执行</p>

<pre><code>psql -c "select pg_start_backup('level',true)"

rsync -ac DATADIR SLAVEHOST:SLAVEDATADIR --exclude postmaster.pid

psql -c "select pg_stop_backup()"
</code></pre></li>
</ol>


<h5>slave端</h5>

<ol>
<li><p>修改postgresql.conf</p>

<pre><code>hot_standby=on
</code></pre></li>
<li><p>新增recovery.conf配置文件</p>

<pre><code>cp &lt;PGROOT&gt;/share/recovery.conf.sample &lt;DATADIR&gt;/recovery.conf
</code></pre></li>
<li><p>修改recovery.conf</p>

<pre><code>standby_mode='on'

primary_conninfo='host=&lt;HOST of MASTER&gt; port=&lt;PORT of MASTER&gt; user=&lt;USER&gt;'
</code></pre></li>
<li><p>启动</p></li>
</ol>


<h4>3. 验证</h4>

<h5>方式一</h5>

<ul>
<li><p>在master上执行</p>

<pre><code>psql -c "select pg_current_xlog_location()"
</code></pre></li>
<li><p>在slave上执行</p>

<pre><code>psql -c "select pg_last_xlog_receive_location()"

psql -c "select pg_last_xlog_replay_location()"
</code></pre></li>
</ul>


<p>通过对比可以看到replicate的进度</p>

<h5>方式二</h5>

<ul>
<li>在master上执行<code>ps -ef|grep sender</code></li>
<li>在slave上执行<code>ps -ef|grep receiver</code></li>
</ul>


<p>同样，通过对比可以看到replicate的进度</p>

<h4>4. 参考</h4>

<p><a href="http://www.postgresql.org/docs/9.1/static/app-initdb.html">http://www.postgresql.org/docs/9.1/static/app-initdb.html</a>
<a href="http://www.postgresql.org/docs/9.1/static/multibyte.html#MULTIBYTE-CHARSET-SUPPORTED">http://www.postgresql.org/docs/9.1/static/multibyte.html#MULTIBYTE-CHARSET-SUPPORTED</a>
<a href="http://wiki.postgresql.org/wiki/Streaming_Replication">http://wiki.postgresql.org/wiki/Streaming_Replication</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[refactor database design]]></title>
    <link href="http://notcode.github.io/blog/2013/10/13/refactor-datebase-design/"/>
    <updated>2013-10-13T19:40:00+08:00</updated>
    <id>http://notcode.github.io/blog/2013/10/13/refactor-datebase-design</id>
    <content type="html"><![CDATA[<h4>原来的设计</h4>

<p>最近被临时调入一个项目，任务是重写后台计算程序, 所以要保持现有的接口和数据库设计。
原有的数据库被设计成每个task一张表，表名为<code>&lt;prefix&gt;_&lt;taskid&gt;</code>，简单说明一下:</p>

<blockquote><ul>
<li>prefix 用于区别报表类型，每个task有10多种报表类型</li>
<li>taskid 整数，用于标识task
每个task有一个开始日期和结束日期，在这个日期区间内，每天计算一次该task的报表。
每个table都有date列, 表明该行记录是哪一天的计算结果</li>
</ul>
</blockquote>

<!-- more -->


<h4>新的设计</h4>

<p>后台重构后，需要将修改数据库结构，表名为<code>&lt;prefix&gt;_&lt;date&gt;</code>，表内有个taskid指明该条记录属于哪个task.
而为了不影响前端访问数据库展示报表，希望不要修改表结构。</p>

<h4>解决方案</h4>

<ul>
<li>预先创建一组名为<code>&lt;prefix&gt;</code>的表,每天的<code>&lt;prefix&gt;_&lt;date&gt;</code>继承自<code>&lt;prefix&gt;</code>.</li>
<li>为了不影响前端，每个task创建一个view:

<blockquote><p>create view &lt;prefix&gt;&lt;taskid&gt; as select * from &lt;prefix&gt; where taskid=&lt;taskid&gt;</p></blockquote></li>
</ul>


<p>前端都没有察觉到后台数据库结构变了，后台程序有可以按照希望的方式建表。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Be careful with mapreduce while writing into database]]></title>
    <link href="http://notcode.github.io/blog/2013/10/13/write-into-database-in-mapreduce-job/"/>
    <updated>2013-10-13T10:04:00+08:00</updated>
    <id>http://notcode.github.io/blog/2013/10/13/write-into-database-in-mapreduce-job</id>
    <content type="html"><![CDATA[<h3>A Strange Case</h3>

<p>Recently we come across a problem when writing into database in mapreduce jobs.
The job gets lots of failure attempt, though succeeds finally.
We reviewed the source code of job, nothing seemed suspicious, there must be something wrong in our cluster.</p>

<p>So we reproduce the scenario.</p>

<!-- more -->


<h3>Crime scene investigate</h3>

<h5>Let&rsquo;s check the log at first.</h5>

<p>From the web console of jobtracker, we find some error logs emitted by the failure attempts.
The logs tell that inserting operation can&rsquo;t be commited because there is already a row in the table, with same primary key.</p>

<h5>What about the job side?</h5>

<p>The job writing into database is a map-only job, and the written table has a primary key on multiple columns.
The input data is guaranted unique on the primary key, so there should be no conflits while executing sql like <code>'insert into ...'</code></p>

<p>We notice that all of the failure attempts&rsquo;s id is greater than 0, that remind me a feature called peculative task in hadoop.
The insert confliction is caused by this feature.</p>

<p>Bingo! We find the killer!</p>

<h3>Close the case</h3>

<p>After close speculative task by <code>job.setMapSpeculativeExecution(false)</code>, the job succeeds silently.</p>

<p>How lucky that the table is created with a primary key!
Otherwise, we will get multiple occurence of the same record silently.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Replica strategy in hdfs is not good enough]]></title>
    <link href="http://notcode.github.io/blog/2013/09/07/replica-strategy-in-hdfs-is-not-good/"/>
    <updated>2013-09-07T19:02:00+08:00</updated>
    <id>http://notcode.github.io/blog/2013/09/07/replica-strategy-in-hdfs-is-not-good</id>
    <content type="html"><![CDATA[<h3>Two methods of Replica</h3>

<p>I&rsquo;ve known two methods of replica in distributed storage system.
One is like hadoop, which distributes the three replicas of a block on three different nodes.
The other is like mongodb, which store data into shardings with three nodes in each sharding.These three nodes in the same sharding are identical.</p>

<p>Both of the two strategy has a &ldquo;at most two dead node&rdquo; tolerance,that meanings if one or two node in cluster crash,all the data is still available. But what happen to three nodes?</p>

<!-- more -->


<h3>Think it for a while</h3>

<p>Suppose there are N nodes and B blocks in cluster. What&rsquo;s the probability of availability with three nodes lost?</p>

<ul>
<li>probability in hadoop cluster</li>
</ul>


<p>For one block,the probability that not all three replicas of this block is on the three dead nodes is:</p>

<pre><code>1-6/[n(n-1)(n-2)]
</code></pre>

<p>The cluster is available with three node lost means all block is available,and the probability is :</p>

<pre><code>(1-6/[n(n-1)(n-2)])^b
</code></pre>

<ul>
<li>probability in mongodb cluster</li>
</ul>


<p>The nodes number is N, shardings number should be N/3. The probability that cluster is not available is 1/[(N/3)(N/3)],
and the opposite is :</p>

<pre><code>1-1/[(N/3)(N/3)]
</code></pre>

<h3>Which is better</h3>

<p>  If N=20,B=10k,which is better?</p>

<ul>
<li>probability in hadoop is: 0.0154%</li>
<li>probability in mongo is: 99.7%</li>
</ul>


<p>See,the tolerance in hadoop is not good enough.</p>

<p>PS: Actually when there are 20 nodes in a cluster,the number of blocks is far greater than 10K.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mongodb performance tuning]]></title>
    <link href="http://notcode.github.io/blog/2013/08/08/mongodb-performance-tuning/"/>
    <updated>2013-08-08T09:47:00+08:00</updated>
    <id>http://notcode.github.io/blog/2013/08/08/mongodb-performance-tuning</id>
    <content type="html"><![CDATA[<h4>1.背景</h4>

<p>mongodb的写性能很一般,即使采用bulk insert，也达不到我们的业务需求。
另外，mongodb有一个DB粒度的读写锁,因此采用并发写也无法提高写性能。因为读写锁的关系，在有写负载较高的情况下,读性能也被拉低了。</p>

<p>引自mongodb官网:</p>

<blockquote><p>Beginning with version 2.2, MongoDB implements locks on a per-database basis for most read and write operations.</p></blockquote>

<!-- more -->


<h4>2.如何优化</h4>

<p>折腾了两天，最终的优化方案如下：</p>

<ul>
<li>使用replica set，读写分离</li>
</ul>


<p> replica set可以避免读写竞争，保证mongodb正常的读写性能。而且为了HA，replica set是必须要做的，所以没有测试replica set对性能影响。</p>

<ul>
<li>对collection做shard，提高写性能</li>
</ul>


<p>做shard能近似线性的提高写速度，在做线性扩展时，可以通过增加shard来达到预期。
但要如果想将写速度提高1~2个数量级，shard数量要x10或x100，代价太高。</p>

<ul>
<li>合并document,减少insert次数</li>
</ul>


<p>终极大招还是这条策略。将原来的document10个一组,合并成一个document，insert的次数降了一个数量级，写速度便不再是问题。</p>

<h4>3.shard benchmark</h4>

<p>对shard做了比较简单的测试，只是验证一下shard的效果。结果如下：</p>

<p>写进程并发数:8</p>

<ul>
<li><p>没有shard,7000 inserts/sec</p></li>
<li><p>2个shard,12000 inserts/sec</p></li>
<li><p>4个shard,16000 inserts/sec</p></li>
</ul>


<p>测试过程中，mongodb的写速度不是很稳定。</p>

<p><em>测试代码:</em></p>

<pre><code>var mongo=require('mongodb');
var util=require('util');
var fs=require('fs');
var STEP=require('./step');

var collection;
function loop(){
    var d=new Date();
    var s=100000;
    STEP(   
        function(){
            var group=this.group();
            for(var i=0;i&lt;s;i++){
                collection.insert({k:i},group());
            }
        },
        function(err,res){
            if(err){throw err;}
            console.log('TPS:\t'+s*1000.0/(new Date()-d))
            setTimeout(loop,10);
        }
    );  
}   
mongo.connect('mongodb://mongo.test.clouds.com:27017/x?w=1',function(err,db){
    if(err){throw err;}
    db.collection('a',function(err,c){
        if(err){throw err;}
        collection=c;
        loop();
    });
});
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在CentOS 5.3 中搭建kvm虚拟机]]></title>
    <link href="http://notcode.github.io/blog/2013/07/20/setup-kvm-environment-on-centos-5-dot-3/"/>
    <updated>2013-07-20T15:41:00+08:00</updated>
    <id>http://notcode.github.io/blog/2013/07/20/setup-kvm-environment-on-centos-5-dot-3</id>
    <content type="html"><![CDATA[<h2>0.准备环境</h2>

<ol>
<li><p>确认cpu是否支持硬件虚拟化</p>

<pre><code>grep -o 'vmx\|svm' /proc/cpuinfo
</code></pre>

<p>如果有输出，表示cpu可以支持。intel的cpu会输出vmx，amd的cpu输出svm.</p></li>
</ol>


<!-- more -->


<ol>
<li><p>设置BIOS，开启虚拟化。</p>

<p>平时修改BIOS的操作很容易，重启进BIOS即可。但由于现在是远程登录到server上,需要远程修改BIOS,可以按照如下操作进行.</p>

<p>查看BIOS是否已经开启虚拟化选项:</p>

<pre><code>omreport chassis biossetup|grep Virtual
</code></pre>

<p>设置BIOS开启虚拟化：</p>

<pre><code>omconfig chassis biossetup attribute=cpuvt setting=enabled
</code></pre></li>
<li><p>关闭selinux</p>

<p>修改/etc/sysconfig/selinux:</p>

<pre><code>SELINUX=disable
</code></pre>

<p>重启server</p></li>
</ol>


<h2>1.安装kvm及启动服务</h2>

<ol>
<li><p>安装</p>

<pre><code>yum groupinstall KVM
</code></pre></li>
<li><p>检查kvm module是否加载</p>

<pre><code>lsmod|grep kvm
</code></pre>

<p>输出</p>

<pre><code>kvm_intel              85256  2 
kvm                   225824  2 ksm,kvm_intel
</code></pre>

<p>如果没有加载，可以手动加载</p>

<pre><code>modprobe kvm_intel
</code></pre></li>
<li><p>开启libvirtd服务</p>

<pre><code> /etc/init.d/libvirtd start
 chkconfig libvirtd on #start at boot
</code></pre></li>
</ol>


<h2>2.配置网络桥接</h2>

<ol>
<li><p>编辑/etc/sysconfig/network-scripts/ifcfg-eth0:</p>

<pre><code>DEVICE=eth0
BOOTPROTO=none
HWADDR=78:2B:CB:10:B3:14
ONBOOT=yes
TYPE=Ethernet
NM_CONTROLLED=no
BRIDGE=br0
</code></pre></li>
<li><p>编辑/etc/sysconfig/network-scripts/ifcfg-br0:</p>

<pre><code>DEVICE=br0
BOOTPROTO=static
ONBOOT=yes
TYPE=Bridge
NETMASK=255.255.255.0
IPADDR=192.168.6.88
NM_CONTROLLED=no
DELAY=0
</code></pre></li>
<li><p>重启网络</p>

<pre><code>service network restart
</code></pre></li>
</ol>


<h2>3.安装guest</h2>

<p>这里使用virt-manager远程安装一个虚拟机。virt-manager是一个图形化的工具，可以方便的安装、管理虚拟机。</p>

<ol>
<li><p>连接到server</p>

<p>终端下执行：</p>

<pre><code>virt-manager -c qemu+ssh://username@server-host/system
</code></pre></li>
<li><p>在弹出的图形界面中，按照向导一步一步安装即可。</p>

<p>要求填写的虚拟机名字，也叫domain,在通过vir×工具管理时，会用的该名字。</p>

<p>在选择网络的时候，选择我们配置的网桥.</p></li>
<li><p>安装完之后会提示重启，进入虚拟机后，需要配置一下ip地址</p></li>
</ol>


<h2>4.其他工具</h2>

<p>以下工具都可以通过ssh远程使用,只要指定正确的URI:<code>qemu+ssh://username@server/system</code></p>

<ol>
<li><p>virsh</p>

<p>命令行的virt-manager</p></li>
<li><p>virt-viewer</p>

<p>可以直接连接到虚拟机的图形界面.例如：</p>

<pre><code>virt-viewer -c URI domain
</code></pre></li>
<li><p>virt-install</p>

<p>命令行的安装工具,需要配置virt-viewer使用。可以将已有的磁盘镜像加入到vir*工具的管理中</p></li>
<li><p>virt-clone</p>

<p>用于克隆虚拟机镜像,克隆后的镜像可以通过vir*工具管理</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[modeline: vim configuration per file]]></title>
    <link href="http://notcode.github.io/blog/2013/07/02/modeline-vim-configuration-per-file/"/>
    <updated>2013-07-02T22:10:00+08:00</updated>
    <id>http://notcode.github.io/blog/2013/07/02/modeline-vim-configuration-per-file</id>
    <content type="html"><![CDATA[<h2>简介</h2>

<p>vim有一个叫做modeline的功能，它允许对单独的文件设置vim变量。当用vim打开文件时，这些变量便可生效。</p>

<p>当编辑python文件时，必须保证编辑环境的缩进和文件中原有的缩进一致。有多个开发人员协作时，缩进不一致的问题经常发生。
使用modeline可以解决这样的问题。</p>

<p>具体做法如下：</p>

<pre><code>#!/usr/bin/env python2.7
# vim: ts=4 sw=4 et
</code></pre>

<!-- more -->


<h2>语法</h2>

<p>modeline的语法如下：</p>

<pre><code>[text]{white}{vi:|vim:|ex:}[white]{options}
</code></pre>

<ul>
<li>[text]            any text or empty</li>
<li>{white}           at least one blank character (<Space> or <Tab>)</li>
<li>{vi:|vim:|ex:}    the string &ldquo;vi:&rdquo;, &ldquo;vim:&rdquo; or &ldquo;ex:&rdquo;</li>
<li>[white]           optional white space</li>
<li>{options}         a list of option settings, separated with white space or &lsquo;:&rsquo;, where each part between &lsquo;:&rsquo; is the argument for a &ldquo;:set&rdquo; command (can be empty)</li>
</ul>


<h2>使用范围</h2>

<p>modeline只在文件开头，或者末尾的N行有效，N默认为5，可以通过查看modelines变量得到</p>

<pre><code>:set modelines?
</code></pre>
]]></content>
  </entry>
  
</feed>
